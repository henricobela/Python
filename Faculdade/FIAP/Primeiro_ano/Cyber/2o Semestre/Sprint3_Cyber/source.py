import streamlit as st

# Image preprocessing
from skimage.transform import resize, rescale
from skimage.feature import hog
from skimage.io import imread
from skimage.color import rgba2rgb
import skimage

# Model training | Sklearn
from sklearn.model_selection import train_test_split
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import cross_val_predict
from sklearn.preprocessing import StandardScaler, Normalizer
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score

# Data analysis
import pandas as pd
import numpy as np

# Data Visualization
import matplotlib.pyplot as plt

# Other
# from google.colab import files
from collections import Counter
import joblib, os


def resize_all(src, pklname, include, width=300, height=None):
    """
    load images from path, resize them and write them as arrays to a dictionary,
    together with labels and metadata. The dictionary is written to a pickle file
    named '{pklname}_{width}x{height}px.pkl'.

    Parameter
    ---------
    src: str
        path to data
    pklname: str
        path to output file
    width: int
        target width of the image in pixels
    include: set[str]
        set containing str
    """

    height = height if height is not None else width

    data = dict()
    data["description"] = "resized ({0}x{1})face images in rgb".format(
        int(width), int(height)
    )
    data["label"] = []
    data["filename"] = []
    data["data"] = []

    pklname = f"{pklname}_{width}x{height}px.pkl"

    # read all images in PATH, resize and write to DESTINATION_PATH
    for subdir in os.listdir(src):
        if subdir in include:
            print(subdir)
            current_path = os.path.join(src, subdir)

            for file in os.listdir(current_path):
                if file[-3:] in {"jpg", "png"}:
                    im = imread(os.path.join(current_path, file))
                    # If image is in RGBA scale turn it into RGB
                    if im.shape[2] > 3:
                        im = rgba2rgb(im)
                    im = resize(im, (width, height))  # [:,:,::-1]
                    data["label"].append(subdir)
                    data["filename"].append(file)
                    data["data"].append(im)

        joblib.dump(data, pklname)


# Display sample folders
data_path = "./Image"
os.listdir(data_path)

# Create dataset
base_name = "faces"
width = 200

include = {"Fake", "Real"}
resize_all(src=data_path, pklname=base_name, width=width, include=include)


# Print summary
data = joblib.load(f"{base_name}_{width}x{width}px.pkl")

print("number of samples: ", len(data["data"]))
print("keys: ", list(data.keys()))
print("description: ", data["description"])
print("image shape: ", data["data"][0].shape)
print("labels:", np.unique(data["label"]), "\n")

Counter(data["label"])


labels = np.unique(data["label"])

# set up the matplotlib figure and axes, based on the number of labels
fig, axes = plt.subplots(1, len(labels))
fig.set_size_inches(15, 4)
fig.tight_layout()

# Make a plot for every label type. The index method returns the
# index of the first item corresponding to its search string, label in this case
for ax, label in zip(axes, labels):
    idx = data["label"].index(label)

    ax.imshow(data["data"][idx])
    ax.axis("off")
    ax.set_title(label)


X = np.array(data["data"])
y = np.array(data["label"])

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, shuffle=True, random_state=42
)


class RGB2GrayTransformer(BaseEstimator, TransformerMixin):
    """
    Convert an array of RGB images to grayscale
    """

    def __init__(self):
        pass

    def fit(self, X, y=None):
        """returns itself"""
        return self

    def transform(self, X, y=None):
        """perform the transformation and return an array"""
        return np.array([skimage.color.rgb2gray(img) for img in X])


class HogTransformer(BaseEstimator, TransformerMixin):
    """
    Expects an array of 2d arrays (1 channel images)
    Calculates hog features for each img
    """

    def __init__(
        self,
        y=None,
        orientations=9,
        pixels_per_cell=(8, 8),
        cells_per_block=(3, 3),
        block_norm="L2-Hys",
    ):
        self.y = y
        self.orientations = orientations
        self.pixels_per_cell = pixels_per_cell
        self.cells_per_block = cells_per_block
        self.block_norm = block_norm

    def fit(self, X, y=None):
        return self

    def transform(self, X, y=None):
        def local_hog(X):
            return hog(
                X,
                orientations=self.orientations,
                pixels_per_cell=self.pixels_per_cell,
                cells_per_block=self.cells_per_block,
                block_norm=self.block_norm,
            )

        try:  # parallel
            return np.array([local_hog(img) for img in X])
        except:
            return np.array([local_hog(img) for img in X])


grayify = RGB2GrayTransformer()
hogify = HogTransformer(
    pixels_per_cell=(14, 14),
    cells_per_block=(2, 2),
    orientations=9,
    block_norm="L2-Hys",
)
scalify = StandardScaler()

# call fit_transform on each transform converting X_train step by step
X_train_gray = grayify.fit_transform(X_train)
X_train_hog = hogify.fit_transform(X_train_gray)
X_train_prepared = scalify.fit_transform(X_train_hog)

print(X_train_prepared.shape)

# create an instance of each transformer
scalify = StandardScaler()

# call fit_transform on each transform converting X_train step by step
X_train_gray = grayify.fit_transform(X_train)
X_train_hog = hogify.fit_transform(X_train_gray)
X_train_prepared = scalify.fit_transform(X_train_hog)

print(X_train_prepared.shape)

sgd_clf = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3)
sgd_clf.fit(X_train_prepared, y_train)


file_name = "cnh_clf.joblib.pkl"
_ = joblib.dump(sgd_clf, file_name, compress=9)

# Load classifier
clf = joblib.load(file_name)

# Load a new photo
clf = joblib.load(file_name)
import streamlit as st


# Load a new photo
def classify_photo(fn):
    # for fn in uploaded.keys():
    #     print(f'Uploaded file "{fn}" with length {len(uploaded[fn])} bytes')
    # Open and preprocess photo
    im = imread(fn)
    if im.shape[2] > 3:
        im = rgba2rgb(im)
    im = resize(im, (200, 200))

    # joblib.dump(im, f"{fn.split('.')[0]}.pkl")
    # data = joblib.load(f'{fn.split(".")[0]}.pkl')
    data = np.array(im)
    grayify = RGB2GrayTransformer()
    hogify = HogTransformer(
        pixels_per_cell=(14, 14),
        cells_per_block=(2, 2),
        orientations=9,
        block_norm="L2-Hys",
    )

    data_gray = grayify.transform([data])
    data_hog = hogify.transform(data_gray)

    prediction = clf.predict(data_hog)

    return prediction[0]


# print('\nClassifying...')
# print(f'A foto Ã© [{prediction[0]}]')
