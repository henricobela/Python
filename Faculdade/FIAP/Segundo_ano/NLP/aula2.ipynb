{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "from spacy.lang.pt.examples import sentences\n",
    "\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/henricobela/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"rslp\")\n",
    "# !python -m spacy download pt_core_news_sm\n",
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amigos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amigas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amizade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carreira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>carreiras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tempestade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cavaleira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>irmão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>irmã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>carro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>carroça</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_fp\n",
       "0       amigos\n",
       "1       amigas\n",
       "2      amizade\n",
       "3     carreira\n",
       "4    carreiras\n",
       "5   tempestade\n",
       "6    cavaleira\n",
       "7        irmão\n",
       "8         irmã\n",
       "9        carro\n",
       "10     carroça"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_palavras_input_fp = pd.DataFrame(['amigo', 'amizade', 'estudante', 'esquema','carnaval','carnavalesco', 'cavaleira', 'carreiras', 'tempestade'], columns=['original_fp'])\n",
    "df_palavras_input_fp = pd.DataFrame(\n",
    "    [\n",
    "        \"amigos\",\n",
    "        \"amigas\",\n",
    "        \"amizade\",\n",
    "        \"carreira\",\n",
    "        \"carreiras\",\n",
    "        \"tempestade\",\n",
    "        \"cavaleira\",\n",
    "        \"irmão\",\n",
    "        \"irmã\",\n",
    "        \"carro\",\n",
    "        \"carroça\",\n",
    "    ],\n",
    "    columns=[\"original_fp\"],\n",
    ")\n",
    "df_palavras_input_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_fp</th>\n",
       "      <th>nltk_stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amigos</td>\n",
       "      <td>amig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amigas</td>\n",
       "      <td>amig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amizade</td>\n",
       "      <td>amizad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carreira</td>\n",
       "      <td>carr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>carreiras</td>\n",
       "      <td>carr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tempestade</td>\n",
       "      <td>tempestad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cavaleira</td>\n",
       "      <td>caval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>irmão</td>\n",
       "      <td>irm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>irmã</td>\n",
       "      <td>irmã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>carro</td>\n",
       "      <td>carr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>carroça</td>\n",
       "      <td>carroç</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_fp nltk_stemmer\n",
       "0       amigos         amig\n",
       "1       amigas         amig\n",
       "2      amizade       amizad\n",
       "3     carreira         carr\n",
       "4    carreiras         carr\n",
       "5   tempestade    tempestad\n",
       "6    cavaleira        caval\n",
       "7        irmão          irm\n",
       "8         irmã         irmã\n",
       "9        carro         carr\n",
       "10     carroça       carroç"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_palavras_input_fp[\"nltk_stemmer\"] = [\n",
    "    stemmer.stem(palavra) for palavra in df_palavras_input_fp[\"original_fp\"]\n",
    "]\n",
    "df_palavras_input_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(str([palavra for palavra in df_palavras_input_fp[\"original_fp\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amigos', 'amigas', 'amizade', 'carreira', 'carreiras', 'tempestade', 'cavaleira', 'irmão', 'irmã', 'carro', 'carroça']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_fp</th>\n",
       "      <th>nltk_stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amigos</td>\n",
       "      <td>amig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amigas</td>\n",
       "      <td>amig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amizade</td>\n",
       "      <td>amizad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carreira</td>\n",
       "      <td>carr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>carreiras</td>\n",
       "      <td>carr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tempestade</td>\n",
       "      <td>tempestad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cavaleira</td>\n",
       "      <td>caval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>irmão</td>\n",
       "      <td>irm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>irmã</td>\n",
       "      <td>irmã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>carro</td>\n",
       "      <td>carr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>carroça</td>\n",
       "      <td>carroç</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_fp nltk_stemmer\n",
       "0       amigos         amig\n",
       "1       amigas         amig\n",
       "2      amizade       amizad\n",
       "3     carreira         carr\n",
       "4    carreiras         carr\n",
       "5   tempestade    tempestad\n",
       "6    cavaleira        caval\n",
       "7        irmão          irm\n",
       "8         irmã         irmã\n",
       "9        carro         carr\n",
       "10     carroça       carroç"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_palavras_input_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (10) does not match length of index (11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_palavras_input_fp[\u001b[39m\"\u001b[39;49m\u001b[39mspacy_lemma\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     token\u001b[39m.\u001b[39mlemma_ \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mpos_ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNOUN\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m ]\n\u001b[1;32m      4\u001b[0m df_palavras_input_fp\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4176\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4912\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4915\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4916\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (10) does not match length of index (11)"
     ]
    }
   ],
   "source": [
    "df_palavras_input_fp[\"spacy_lemma\"] = [\n",
    "    token.lemma_ for token in doc if token.pos_ == \"NOUN\"\n",
    "]\n",
    "df_palavras_input_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"Eu quero ter aulas na faculdade aprender e ter aprendizado enquanto posso comprar um carro caro\"\n",
    "sent2 = \"Eu quero ir para aula com o carro do meu caro amigo e ver a aula aprender conteúdos felizes que promovam minha aprendizagem\"\n",
    "tokens1 = [t.lower() for t in sent1.split(\" \")]\n",
    "tokens2 = [t.lower() for t in sent2.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eu',\n",
       " 'quero',\n",
       " 'ter',\n",
       " 'aulas',\n",
       " 'na',\n",
       " 'faculdade',\n",
       " 'aprender',\n",
       " 'e',\n",
       " 'ter',\n",
       " 'aprendizado',\n",
       " 'enquanto',\n",
       " 'posso',\n",
       " 'comprar',\n",
       " 'um',\n",
       " 'carro',\n",
       " 'caro']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eu',\n",
       " 'quero',\n",
       " 'ir',\n",
       " 'para',\n",
       " 'aula',\n",
       " 'com',\n",
       " 'o',\n",
       " 'carro',\n",
       " 'do',\n",
       " 'meu',\n",
       " 'caro',\n",
       " 'amigo',\n",
       " 'e',\n",
       " 'ver',\n",
       " 'a',\n",
       " 'aula',\n",
       " 'aprender',\n",
       " 'conteúdos',\n",
       " 'felizes',\n",
       " 'que',\n",
       " 'promovam',\n",
       " 'minha',\n",
       " 'aprendizagem']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e', 'caro', 'aprender', 'eu', 'quero', 'carro'}\n",
      "{'para', 'meu', 'conteúdos', 'e', 'posso', 'aprender', 'aulas', 'ver', 'aprendizado', 'amigo', 'enquanto', 'do', 'ir', 'aprendizagem', 'comprar', 'que', 'faculdade', 'aula', 'ter', 'na', 'a', 'promovam', 'eu', 'felizes', 'caro', 'com', 'o', 'minha', 'um', 'carro', 'quero'}\n"
     ]
    }
   ],
   "source": [
    "set1 = set(tokens1)\n",
    "set2 = set(tokens2)\n",
    "set_union = set1.union(set2)\n",
    "set_intersection = set1.intersection(set2)\n",
    "print(set_intersection)\n",
    "print(set_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple está querendo comprar uma startup do Reino Unido por 100 milhões de dólares\n",
      "Apple PROPN nsubj\n",
      "está AUX aux\n",
      "querendo VERB ROOT\n",
      "comprar VERB xcomp\n",
      "uma DET det\n",
      "startup NOUN obj\n",
      "do ADP case\n",
      "Reino PROPN nmod\n",
      "Unido PROPN flat:name\n",
      "por ADP case\n",
      "100 NUM obl\n",
      "milhões NUM flat\n",
      "de ADP case\n",
      "dólares NOUN nmod\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "doc = nlp(sentences[0])\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed sent1: ['eu', 'gostar', 'de', 'estudar']\n",
      "preprocessed sent2: ['eu', 'querer', 'ir', 'para', 'aula', 'com', 'carro', 'de o', 'caro', 'amigo', 'e', 'ver', 'aula', 'aprender', 'conteúdo', 'feliz', 'que', 'promor', 'aprendizagem']\n"
     ]
    }
   ],
   "source": [
    "def preprocess(sentence):\n",
    "    result = []\n",
    "    tokens = nlp(sentence)\n",
    "    for token in tokens:\n",
    "        # remove determiners and punctuation or spaces\n",
    "        if token.pos_ in [\"PUNCT\", \"SPACE\", \"DET\"]:\n",
    "            continue\n",
    "        else:\n",
    "            # the lemma of pronouns is stored as '-PRON-' in spacy; we want the actual pronoun\n",
    "            if token.pos_ == \"PRON\":\n",
    "                result.append(token.text.lower())\n",
    "            else:\n",
    "                result.append(token.lemma_)\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"preprocessed sent1: {}\".format(preprocess(\"Eu gosto de estudar\")))\n",
    "print(\"preprocessed sent2: {}\".format(preprocess(sent2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_set1 = preprocess(sent1)\n",
    "\n",
    "lemma_set2 = preprocess(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1_lemma = set(lemma_set1)\n",
    "set2_lemma = set(lemma_set2)\n",
    "set_union_lemma = set1.union(set2_lemma)\n",
    "set_intersection_lemma = set1_lemma.intersection(set2_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Coefficient (depois do lemma): 0.25\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Jaccard Coefficient (depois do lemma): {}\".format(\n",
    "        len(set_intersection_lemma) / len(set_union_lemma)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28\n"
     ]
    }
   ],
   "source": [
    "def jaccard_coefficient(sent1, sent2, preprocessor=preprocess):\n",
    "    tokens1 = preprocessor(sent1)\n",
    "    tokens2 = preprocessor(sent2)\n",
    "    set1 = set(tokens1)\n",
    "    set2 = set(tokens2)\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "print(jaccard_coefficient(sent1,sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "respostas = \"\"\"Modelos \n",
    "Utilização\n",
    "Tokenizacao\n",
    "GPT\n",
    "DB como contexto em NLP\n",
    "Análise de sentimento\n",
    "NLP com áudio\n",
    "Tokenization\n",
    "Geração de NL\n",
    "Classificação\n",
    "Como funciona GPT\n",
    "Caso de uso real com NLP\n",
    "Deploy de modelos\n",
    "Arquitetura de redes NLP\n",
    "Bibliotecas\n",
    "Código\n",
    "Girias\n",
    "Utilizar áudio para inter\n",
    "Manter conversa entre IA\n",
    "Técnicas\n",
    "Tratamentos\n",
    "Infraestrutura\n",
    "Arquitetura\n",
    "Qualidade de metadados\n",
    "Qualidade de conceitos de\n",
    "Calculo por trás do nlp\n",
    "Bag of words\n",
    "Aprofundamento em NLP\n",
    "Saudável\n",
    "Aprender em um ritmob\n",
    "Salles\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
